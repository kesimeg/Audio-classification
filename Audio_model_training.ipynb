{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_num(name):\n",
    "    label = name.split(\".\")[0].split(\"_\")[1]\n",
    "    if label == 'gui':\n",
    "        return 0\n",
    "    elif label == 'hi':\n",
    "        return 1\n",
    "    elif label == 'lau':\n",
    "        return 2\n",
    "    elif label == 'sax':\n",
    "        return 3\n",
    "    elif label == 'vio':\n",
    "        return 4\n",
    "\n",
    "class Audio_dataset(Dataset):\n",
    "\n",
    "\n",
    "    def __init__(self,file_dir):\n",
    "\n",
    "\n",
    "        self.file_dir = file_dir\n",
    "        \n",
    "        self.files = os.listdir(self.file_dir)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        x = self.files[idx]\n",
    "        audio = torch.from_numpy(torch.load(os.path.join(self.file_dir,x)))\n",
    "\n",
    "        audio = audio.unfold(1,50,1) # apply a window at each time-step\n",
    "\n",
    "        audio = audio.permute(1,0,2)\n",
    "\n",
    "        label = label_to_num(x)\n",
    "        \n",
    "        return audio,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = True # log the accuracies and loss\n",
    "log_w = True # log the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "dataset_train = Audio_dataset(file_dir=\"./data/melspectrogram/train\")\n",
    "\n",
    "dataset_valid = Audio_dataset(file_dir=\"./data/melspectrogram/validation\")\n",
    "train_loader = DataLoader(dataset_train, batch_size=1,\n",
    "                        shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(dataset_valid, batch_size=1,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "train_set_size = len(dataset_train)\n",
    "\n",
    "valid_set_size = len(dataset_valid)\n",
    "print(train_set_size)\n",
    "print(valid_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 102, 60, 50]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "audio,label = next(iter(train_loader))\n",
    "print(audio.shape,label) #check shape of the inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a CNN-GRU model, alternatively you can use different models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.audio_encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1, 1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(32, 32, 3, 1, 1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(32, 32, 3, 1, 1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.audio_linear = nn.Sequential(nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Linear(32*7*6,128))\n",
    "\n",
    "        self.gru_hiddend_dim = 128\n",
    "\n",
    "        self.gru = nn.GRU(128, 128, 1, batch_first=True)\n",
    "\n",
    "        self.out = nn.Sequential(nn.Linear(128,5)) # 5 classes\n",
    "\n",
    "    def forward(self,audio_data):\n",
    "\n",
    "\n",
    "        batch_size = audio_data.size(0)\n",
    "\n",
    "        x = self.audio_encoder(audio_data.view(-1,1,60,50))\n",
    "\n",
    "        x = self.audio_linear(x.view(-1,32*7*6))\n",
    "\n",
    "        h0 = torch.ones(1, batch_size, self.gru_hiddend_dim).to(device)\n",
    "        \n",
    "        x, _ = self.gru(x.view((batch_size,-1,128)),h0)# (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        x = x[:,-1,:] # take the last time step for prediction\n",
    "        \n",
    "        prediction = self.out(x.reshape(-1,128))\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 102, 60, 50]) tensor([2])\n"
     ]
    }
   ],
   "source": [
    "audio,label = next(iter(train_loader))\n",
    "print(audio.shape,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" # put everything to cpu just for now to check if model is working\n",
    "model = Net()\n",
    "\n",
    "out = model(audio)\n",
    "print(out.shape) # check the output shape for some input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:17<02:36, 17.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.0617 train_acc: 0.58 val loss:0.6740 val_acc: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:34<02:18, 17.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.6335 train_acc: 0.79 val loss:0.4690 val_acc: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:51<02:01, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.4648 train_acc: 0.85 val loss:0.4535 val_acc: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [01:09<01:43, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.3648 train_acc: 0.89 val loss:0.2960 val_acc: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [01:26<01:26, 17.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2744 train_acc: 0.91 val loss:0.3683 val_acc: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [01:44<01:09, 17.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2431 train_acc: 0.92 val loss:0.2643 val_acc: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [02:01<00:52, 17.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1721 train_acc: 0.95 val loss:0.4827 val_acc: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [02:19<00:34, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1399 train_acc: 0.96 val loss:0.2574 val_acc: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [02:36<00:17, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1130 train_acc: 0.97 val loss:0.2608 val_acc: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:53<00:00, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1013 train_acc: 0.97 val loss:0.2168 val_acc: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "def train_model(model, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    pbar=tqdm(range(0,num_epochs))\n",
    "    for epoch in pbar: \n",
    "        # Each epoch has a training and validation phase\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        # Iterate over data.\n",
    "        for sample in train_loader:\n",
    "            data ,labels = sample\n",
    "            batch_size = data.size(0)\n",
    "            data = data.to(device) \n",
    "\n",
    "            labels = labels.long().to(device)\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(True):\n",
    "\n",
    "                outputs = model(data.float())\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # statistics\n",
    "            running_loss += loss.item() * data.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = running_loss / train_set_size\n",
    "        train_acc = running_corrects.double() / train_set_size\n",
    "        \n",
    "        \n",
    "        model.eval()   # Set model to evaluate mode\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for sample in valid_loader:\n",
    "                data ,labels = sample\n",
    "\n",
    "                data = data.to(device) \n",
    "                labels = labels.long().to(device)\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = model(data)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * data.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "        val_loss = running_loss / valid_set_size\n",
    "        val_acc = running_corrects.double() / valid_set_size\n",
    "\n",
    "        print(\"train loss:{:.4f} train_acc: {:.2} val loss:{:.4f} val_acc: {:.2}\".format(train_loss,train_acc,val_loss,val_acc))\n",
    "        \n",
    "        if log:\n",
    "            log_data = {'epoch': epoch,\n",
    "                't_loss': train_loss,\n",
    "                't_acc':train_acc.cpu().item(),\n",
    "                'v_loss':val_loss,\n",
    "                'v_acc':val_acc.cpu().item(),\n",
    "\n",
    "            }\n",
    "            df = pd.DataFrame(log_data,index=[0])\n",
    "            if epoch==0:\n",
    "                df.to_csv(my_file,index=False,mode=\"a\")\n",
    "            else:\n",
    "                df.to_csv(my_file, header=False,index=False,mode=\"a\")\n",
    "        \n",
    "        if log_w:\n",
    "            torch.save(model.state_dict(), save_dir + \"/model{}.pth\".format(epoch))\n",
    "    return model\n",
    "\n",
    "print(\"Device: \",device)\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # we use cross entropy loss\n",
    "\n",
    "file_name = \"cnn_gru\"\n",
    "save_dir = os.path.join(\"./models\",file_name)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "my_file = file_name + \".csv\" # we will log the accuracy and loss to a csv file\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "model = train_model(model, optimizer,\n",
    "                      num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now after the traning is finished we will evaluate the performance of our model in a better way in another notebook.\n",
    "Remember that in test set samples are not equally distributed so we have calculated the unweighted accuracy for the test set during traning.\n",
    "In the next notebook we will check performance of the model for each indivual class with a confusion matrix. You can try using a different model, hyper parameter to get better results. Also note that our model is overfitting. You can try solving this by adding drop out or L2-regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
